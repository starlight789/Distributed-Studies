
计划：
1. 理解基本原理代码(2d)
2. 理解相关优化代码(2d)
基本核心原理：
1. 选举问题
2. 日志复制与日志recovery
3. 日志压缩snapshot
4. 节点membership管理
相关功能完善：
1. pre-vote
2. 局部性选举优化
3. 最大可用模式（setPeer）
性能优化:
1. pipline log复制
2. leader io慢：write local异步化, read 读取分发优化（会话一致性）
3. 本地log entry写入 batch化
raft思考：
1. 请求幂等：log entry中增加request id，如果request查询存在则忽略，通过duplicate-request-cache来保证response；
2. 本地读取一致性思考：
* 无论从follow还是leader读取都有stale数据风险
* leader的风险在于自身由于网络问题可能已经不是真的leader了
* client采用 w + r > n 来实现
* client的write/read操作返回/携带commited，follow接受到read 的commited的时候，主动发起applied，但是这样数据有滞后性，读取的数据不一定是最新的
注意要点：braft中rpc非常多，不要拘泥于字段限制，理解整体功能流程。
我们还是先从node.cpp来查看比较规矩：
1. 论文思考、学习node内部组成
2. 学习选举流程
raft大佬的思考：
raft内部需要持久化的数据有哪些：
* term: raft的核心数据之一，用于判断当前node的信息是否过时；
* votefor: 需要持久话，一个node在周期内投给一个candidate之后，该term内不应该再投票；这样也可以避免该node 宕机后启动，再次投票导致一致性问题。
* snapshot: 没啥好说的，log entry的压缩
* log entries, 包括log index以及term:
* configure, peer信息:
下面两个是不需要持久化的
* committed index: 选举出新主之后，可以认为主上面的所有log entry都是committed状态，此时也会在新term写入一个空log entry来保证这点。
* apply index: 如果无快照，则为0，有快照，则已经在快照里面保存了；
raft safety准则：
1. election safety: 同一个term下最多只有一个leader被选举出来；（可能有多个，但是这种情况leader无法工作）
2. leader append only: leader不会覆盖或者删除自己的log entry，只能append
3. log matching: 如果两个log的term和index一致，那么内容必定一致，且前面的日志也一直；
4. leader completeness: 如果一个log entry在某个term已经committed了，那么这个log必定存在后续的leader中；
5. state machine safety: 如果一个node已经apply一个log entry到状态机，那么其他节点不会apply相同的index到不通的entry；
这5调准则怎么保证：
1\2：不比多说，选举leader，以及log提交功能限制了；
3. 这里有两个保证，如果一个log entry的term和index一致，则a)该log内容一致;b)之前log日志也一致
a) 这里是由于follow的log都来自leader，所以如果term和index一致，则必定一致
b) 之前的log可能出现不一致，因为可能存在切主，这时leader选出后需要进行log recovery来保证一致；
4\5：一个leader发现某条entry已被提交，则后续所有leader中都一定要有这条entry；这意味着leader中总是有所有的已提交entry；而raft能保证follower中的log最终一定与leader中的一致；所以所有server最终都会有这些已提交entry；而entry只有被提交后才能被state machine执行；所以最终所有的state machine必将按照相同的顺序执行相同的命令.
tips：4，5可以好好琢磨下，log recovery为了保证这点，在leader启动时会追加一个log entry,来保证未committed的log entry立刻committed转变。
基础node数据结构
在node.h内部我们可以看到多个timer，底座是一个基于bthread的repeated_timer_task, 这个子类的特别之处在于timeout之后，会开启一个new thread做处理，并非传统timer一样把处理流程也放在计时内。
计时器分为：ElectionTimer、 VoteTimer、 StepdownTimer、 SnapshotTimer；
除了StepdownTimer，其他从名称都非常好理解，从run函数看，StepdownTimer应该是选举阶段，leader接收更高term的vote req，自主状态转变的计时器，从server.md里我们可以一探究竟：
| election_timer       | 选主定时器，FOLLOWER状态下启用
| vote_timer           | 投票定时器，CANDIDATE状态下启用
| stepdown_timer       | 主切从定时器，LEADER状态下启用
| snapshot_timer       | 快照定时器
从example中我们可以看出，我们想要实现一个带有raft功能的服务，需要做的有一下几点：
1. 依据我们的需求写好对应的file.proto文件
2. 编写对应的on_applied函数，这个函数会在do_committed之后被调用
关于NodeImpl，这个是我们在初始化对应raft服务需要注意的事，简单的说，
class Atomic : public braft::StateMachine
    braft::Node* volatile _node;
    butil::atomic<int64_t> _leader_term;
我们的的服务需要继承braft的状态机，然后在状态机的初始化过程中，初始化raft的Node相关服务，这里Node是怎么和状态机的关联，就是依靠node_options.fsm = this; 整个raft维护一致性是依靠node内部逻辑，下面我们来看下细节实现：
先介绍Node的两个重要的组成部分FSMCaller，Ballot，前者用于维护状态机，后者则是raft节点投票相关的操作，
这里需要raft的基础知识，需要注意的是，applied由FSMCaller维护，而commited_index由Ballot维护;
选举相关，prevote, vote，心跳相关不做解释
node内部涉及到commit以及apply相关的还牵扯到Replicator，所以我们首先仅关注选举流程吧；
* 启动时，除非仅一个node，否则默认等待选举超时触发handle_election_timeout，这里的超时时间很有意思，是哪个定时器由于都是继承的RepeatedTimerTask， 虽然初始设置的time都是基于election_timeout_ms，但是在repeated timer启动的时候，会生产一个随机数，所以即使所有节点同时启动，也会在不同的时刻发起选举超时，然后vote
handle_election_timeout
|- NodeImpl::pre_vote
- 给所有的peers发送发送消息
|- stub.pre_vote // 给所有的peer发送投票请求，异步回调 -> request调用流程在投票环节说
- handle_pre_vote_response
|- 检查节点与请求时是否变换（如果term变了，或者状态变了则skip就行）
|- 如果peer term更高，那么我们应该step_down等待他来vote
|- 然后统一通过VoteBallot 这个投票箱来进行
- _pre_vote_ctx.grant(*it);
|- _pre_vote_ctx.granted() 如果超过半数，那么就选举自己
|-  elect_self; // 发起正式投票
- 状态转变为candidate， current_term++
|- request_peers_to_vote给所有的peers发送vote请求，与prevote在request的区别可能就是current_term增加了
|- handle_request_vote_response，与prevote的主要区别是become_leader
- become_leader: 给所有的peers注册replicate timer，并且发送一个empty entries（实际上与心跳很像，但是内部包含了日志修复）, 来确保log的commited；
handle_pre_vote_request
|- 预投票检查（比正式投票检查少，因为确实不需要一些状态转换）
1. req.term是否比自己的小，是则拒绝
2. log index 比较
|- 把自己的term放入
|- 租约相关信息
handle_request_vote_request
1. 比较term是否比自己小
2. 取得log最新的index, 由于ABA问题，这里需要比较写cur_term与prev_term
3. 比较follower lease租约，如果没有过期，就不投票
4. 如果term新， leader setp_down降级
5. 如果log中req的更新，且没投票过，投票给他，_vote_id记录；保存本地投票结果到本地
prevote gpt知识小结，可以我们关注到，发起方发起prevote的时候，其状态是follower的；
Raft算法的Pre-vote阶段是为了防止网络分区和服务器重启等问题导致的不必要的领导者选举。Pre-vote阶段的条件和要求如下：
发起方条件：
发起方只有在自己的状态为Follower或Candidate，并且在一段时间内没有收到Leader的心跳，才会启动Pre-vote阶段。
发起方在Pre-vote阶段会增加自己的term，并将自己的term和最后一条日志的index和term发送给其他节点。
响应方条件：
响应方接收到Pre-vote请求后，首先会和自己的term进行比较，如果请求的term小于自己的term，则拒绝请求。
如果请求的term等于或大于自己的term，响应方会比较自己的日志和请求中的日志，如果自己的日志比请求中的日志新，也会拒绝请求。
如果请求的term和日志都满足要求，响应方会将自己的状态设置为Follower，并返回同意Pre-vote的响应。
如果发起方收到了大多数节点（包括自己）的同意Pre-vote的响应，那么发起方将进入到真正的领导者选举阶段（vote阶段）。
注意：Pre-vote阶段不会改变节点的状态，也不会改变当前的term，只是一个预先的选举，用于测试是否有可能成功进行领导者选举。
日志复制
日志复制，实际上就是append_entries请求
_send_entries()、_send_empty_entries(bool is_heartbeat) 均会走到last_commited，但是但且仅当ballot完成了超过一般以上的节点grant之后，才会自增committed，这样，在后续的心跳和append entries中，才会继续更新follower节点的状态机。
- Replicator::_fill_common_fields
|- request->set_committed_index(_options.ballot_box->last_committed_index());
带有raft的请求原来是先append entries日志，然后才执行op，我们以example/atomic为例：
AtomicServiceImpl::exchange
- Atomic::exchange
- apply(OP_EXCHANGE, request, response, done);
- Atomic::apply
- butil::IOBufAsZeroCopyOutputStream // 日志序列化
|- NodeImpl::apply
|- LogManager::append_entries
- LeaderStableClosure::Run()
|- _ballot_box->commit_at
|- wakeup_all_waiter(lck); // 唤醒所有的replicator的waiter任务，去执行append entries
tips：
braft使用了bthread的类似生产者消费者队列
// 构建消费者，消费函数是run
bthread::execution_queue_start(&_queue_id,
&execq_opt,
FSMCaller::run,
this)
当一个数据执行完成后，会调用FSM状态机函数
_waiter->on_committed(last_committed_index);
_
|- FSMCaller::on_committed
- bthread::execution_queue_execute(_queue_id, t);
|- 而后会调用do_committed进行append entries发送
日志复制，是如何在follow上面确认的：
在Raft协议中，当leader发送append entries给follower并且收到了成功的响应后，leader会更新自己对应的follower的nextIndex和matchIndex。其中matchIndex记录的是该follower已经写入的日志的最大索引。
一旦leader更新了follower的matchIndex，它就会检查是否存在一个索引 N 和任意大于 N 的索引，使得大于等于半数的follower的matchIndex大于等于N，且索引N的日志条目的任期号等于leader当前的任期。如果存在，那么leader就会将自己的commitIndex更新为这个索引N。
当leader的commitIndex被更新后，leader会将更新后的commitIndex通过append entries RPC发送给所有的follower。当follower收到append entries RPC后，如果发现leader的commitIndex大于自己的commitIndex，那么follower就会将自己的commitIndex更新为leader的commitIndex。
这样，通过leader和follower之间的交互，就可以保证一旦一个日志条目被复制到了大多数的服务器上，那么这个日志条目就会被标记为committed。
通过上面，应该能够理解append entries是怎么发送以及response的，那么什么时候发送append entries请求呢？
tips: _on_rpc_returned是append entries的response函数，再得到对应的
日志Recovery
日志的recovery分为current term与prev term：
* current term的修复主要场景是follower因为故障退出集群，而后恢复后，leader对齐进行follower进行同步；
* prev term是在leader频繁切换+某个follower离线了一段时间的请求下才会出现，leader为每一个follower维护了一个nextId，标识下一个要发送的log index，Follower接收到AppendEntries之后会进行一些一致性检查，检查AppendEntries中指定的LastLogIndex是否一致，如果不一致就会向Leader返回失败。Leader接收到失败之后，会将nextId减1，重新进行发送，直到成功。
https://www.jianshu.com/p/82b9c268688e
在follower接收到append entries之后，需要进行term的判定：
handle_append_entries_request
// 如果prev的日志不匹配，应该需要直接进入log recovery状态
-if (local_prev_log_term != request->prev_log_term())
- 返回失败，并且把follower的term返回给leader
|- response->set_last_log_index(last_index);
|- response->set_success(false);
在leader这端：
Replicator::_on_rpc_returned
- if (!response->success()) {
|- r->_reset_next_index();
|- r->_next_index = response->last_log_index() + 1; 或者  --r->_next_index;
|- r->_send_empty_entries(false);
- Replicator::_fill_common_fields
- _install_snapshot(); 如果本地找不到对应的log index
|- stub.append_entries; 如果找到了则继续append entries
小结：braft的log recovery是比较纯粹的，在follower发现log index或者term不匹配的时候，会直接给leader返回自己的prev log index， 由leader来看当前是否适合install snapshot，如果不合适就继续发送log entries。
这里有个细节：
// 如果follower日志比我少，那我对齐他的日志同步就可以
if (response->last_log_index() + 1 < r->_next_index) {
|- r->_next_index = response->last_log_index() + 1;
// 如果follower日志比我多，那么他上面的一定是old term的，且必定没有committed，我们需要逐个回溯去对齐我们有重复的log index
|- --r->_next_index;
snapshot
snapshot有两种模式：计时模式，接口模式，计量模式（计量模式没有实现，因为实时统计内存是一种相对耗时的操作）
handle_snapshot_timeout()
- do_snapshot
- SnapshotExecutor::do_snapshot
|- 创建snapshot writer
|- SnapshotWriter* writer =
- LocalSnapshotWriter::init
|- SaveSnapshotDone* snapshot_save_done = new SaveSnapshotDone(this, writer, done);
|- if (_fsm_caller->on_snapshot_save(snapshot_save_done) != 0) {
-  FSMCaller::do_snapshot_save
|- SaveSnapshotDone::Run()
libraft内提供了基于文件列表的LocalSnapshotWriter和LocalSnapshotReader默认实现，具体使用方式为：
* 在fsm的on_snapshot_save回调中，将状态数据写入到本地文件中，然后调用SnapshotWriter::add_file将相应文件加入snapshot meta。
* 在fsm的on_snapshot_load回调中，调用SnapshotReader::list_files获取本地文件列表，按照on_snapshot_save的方式进行解析，恢复状态数据。
membership change
参考：https://ku.baidu-int.com/knowledge/HFVrC7hq1Q/pKzJfZczuc/vx_oM591qA/w2qUKQG_6Fl8Bi
目前讨论raft的复制组都是基于一个假设：集群的整体配置是不变的
raft集群是需要支持动态的添加节点的，想想当前的接口，如果当前加入集群非常多的节点，那么可能会出现两个group，同时，由于各个节点的配置的更新是不同步的，这类问题使用2PC提交协议来解决, 具体步骤：
// new_peers and old_peers during all conf-change stages, namely
// STAGE_CATCHING_UP->STAGE_JOINT->STAGE_STABLE
当发现配置变更后，节点会进入STAGE_CATCHING_UP状态；
流程上来说，client通知leader做配置变更：
1. 首先leader会直接应用new conf以及old conf，这里他的状态是转变为了STAGE_CATCHING_UP，此时leader会同时将new conf、old conf配置同时写入log entries并直接应用，本次应用是无需等待follower做投票应用的；
2. 如后续某条普通的entry要想被提交，必须同时存在于大多数的旧配置的server上，和大多数的新配置的server上；
-> 但是在此期间，一个消息想要被应用，decision-making有可能是基于Cold，也有可能是基于Cold+new；
3. 当new+old conf应用的消息，被大多数node接收committed之后，集群就会进入joint-consensus（联合一致性）；
-> 这里意味这后续的leader，必须要有old的大多数+new conf的大多数配置才可以被选举成功；
4. 当大多数new+old conf被接受之后， leader会发送new conf log entries应用，在new_conf应用期间
-> new conf + old conf都是大多数的消息可以接收
-> new conf的大多数消息可以接收
5. 最终 new conf应用后, 集群整体使用new conf来做决策
实质上，将整个集群可能的decison-making依赖的majority状态空间分成了5个阶段，分别是：
old中大多数做决定 →（old中的大多数做决定） 或者 （old和new中的大多数同时做决定）→（old和new中的大多数同时做决定）
→（old和new中的大多数同时做决定） 或者 （new中的大多数做决定）→ new中的大多数做决定
tips：如果变更期间，old conf被选举出leader，后续new conf相关的配置更新之后，该leader必定会step down
除了批量更新new conf，还有一种单点更新的方法：
0. new node追数据；
1. leader直接把新配置Cnew到 old + new个节点上
2. Commit这个新日志之后，就能保证以Cnew工作，在此之前，集群有可能是以Cnew方式工作(leader上是Cnew)，也有可能是以Cold工作 (发生切主，leader上是Cold)
计划：
1. 理解基本原理代码(2d)
2. 理解相关优化代码(2d)

基本核心原理：
1. 选举问题
2. 日志复制与日志recovery
3. 日志压缩snapshot
4. 节点membership管理

相关功能完善：
1. pre-vote
2. 局部性选举优化
3. 最大可用模式（setPeer）

性能优化:
1. pipline log复制
2. leader io慢：write local异步化, read 读取分发优化（会话一致性）
3. 本地log entry写入 batch化

raft思考：
1. 请求幂等：log entry中增加request id，如果request查询存在则忽略，通过duplicate-request-cache来保证response；
2. 本地读取一致性思考：
        * 无论从follow还是leader读取都有stale数据风险
                * leader的风险在于自身由于网络问题可能已经不是真的leader了
        * client采用 w + r > n 来实现
        * client的write/read操作返回/携带commited，follow接受到read 的commited的时候，主动发起applied，但是这样数据有滞后性，读取的数据不一定是最新的


注意要点：braft中rpc非常多，不要拘泥于字段限制，理解整体功能流程。


我们还是先从node.cpp来查看比较规矩：
1. 论文思考、学习node内部组成
2. 学习选举流程


# raft大佬的思考：

raft内部需要持久化的数据有哪些：
* term: raft的核心数据之一，用于判断当前node的信息是否过时；
* votefor: 需要持久话，一个node在周期内投给一个candidate之后，该term内不应该再投票；这样也可以避免该node 宕机后启动，再次投票导致一致性问题。
* snapshot: 没啥好说的，log entry的压缩
* log entries, 包括log index以及term: 
* configure, peer信息:

下面两个是不需要持久化的
* committed index: 选举出新主之后，可以认为主上面的所有log entry都是committed状态，此时也会在新term写入一个空log entry来保证这点。
* apply index: 如果无快照，则为0，有快照，则已经在快照里面保存了；

raft safety准则：
1. election safety: 同一个term下最多只有一个leader被选举出来；（可能有多个，但是这种情况leader无法工作）
2. leader append only: leader不会覆盖或者删除自己的log entry，只能append
3. log matching: 如果两个log的term和index一致，那么内容必定一致，且前面的日志也一直；
4. leader completeness: 如果一个log entry在某个term已经committed了，那么这个log必定存在后续的leader中；
5. state machine safety: 如果一个node已经apply一个log entry到状态机，那么其他节点不会apply相同的index到不通的entry；
这5调准则怎么保证：
1\2：不比多说，选举leader，以及log提交功能限制了；
3. 这里有两个保证，如果一个log entry的term和index一致，则a)该log内容一致;b)之前log日志也一致
  a) 这里是由于follow的log都来自leader，所以如果term和index一致，则必定一致
  b) 之前的log可能出现不一致，因为可能存在切主，这时leader选出后需要进行log recovery来保证一致；
4\5：一个leader发现某条entry已被提交，则后续所有leader中都一定要有这条entry；这意味着leader中总是有所有的已提交entry；而raft能保证follower中的log最终一定与leader中的一致；所以所有server最终都会有这些已提交entry；而entry只有被提交后才能被state machine执行；所以最终所有的state machine必将按照相同的顺序执行相同的命令.

tips：4，5可以好好琢磨下，log recovery为了保证这点，在leader启动时会追加一个log entry,来保证未committed的log entry立刻committed转变。


基础node数据结构
在node.h内部我们可以看到多个timer，底座是一个基于bthread的repeated_timer_task, 这个子类的特别之处在于timeout之后，会开启一个new thread做处理，并非传统timer一样把处理流程也放在计时内。

计时器分为：ElectionTimer、 VoteTimer、 StepdownTimer、 SnapshotTimer；
除了StepdownTimer，其他从名称都非常好理解，从run函数看，StepdownTimer应该是选举阶段，leader接收更高term的vote req，自主状态转变的计时器，从server.md里我们可以一探究竟：
| election_timer       | 选主定时器，FOLLOWER状态下启用
| vote_timer           | 投票定时器，CANDIDATE状态下启用
| stepdown_timer       | 主切从定时器，LEADER状态下启用
| snapshot_timer       | 快照定时器

从example中我们可以看出，我们想要实现一个带有raft功能的服务，需要做的有一下几点：
1. 依据我们的需求写好对应的file.proto文件
2. 编写对应的on_applied函数，这个函数会在do_committed之后被调用
关于NodeImpl，这个是我们在初始化对应raft服务需要注意的事，简单的说，
```
class Atomic : public braft::StateMachine
    braft::Node* volatile _node;
    butil::atomic<int64_t> _leader_term;
```
我们的的服务需要继承braft的状态机，然后在状态机的初始化过程中，初始化raft的Node相关服务，这里Node是怎么和状态机的关联，就是依靠node_options.fsm = this; 整个raft维护一致性是依靠node内部逻辑，下面我们来看下细节实现：


先介绍Node的两个重要的组成部分FSMCaller，Ballot，前者用于维护状态机，后者则是raft节点投票相关的操作，
这里需要raft的基础知识，需要注意的是，applied由FSMCaller维护，而commited_index由Ballot维护;

### 选举相关，prevote, vote，心跳相关不做解释

node内部涉及到commit以及apply相关的还牵扯到Replicator，所以我们首先仅关注选举流程吧；

* 启动时，除非仅一个node，否则默认等待选举超时触发handle_election_timeout，这里的超时时间很有意思，是哪个定时器由于都是继承的RepeatedTimerTask， 虽然初始设置的time都是基于election_timeout_ms，但是在repeated timer启动的时候，会生产一个随机数，所以即使所有节点同时启动，也会在不同的时刻发起选举超时，然后vote

handle_election_timeout
 |- NodeImpl::pre_vote
   \- 给所有的peers发送发送消息
   |- stub.pre_vote // 给所有的peer发送投票请求，异步回调 -> request调用流程在投票环节说
     \- handle_pre_vote_response
      |- 检查节点与请求时是否变换（如果term变了，或者状态变了则skip就行）
      |- 如果peer term更高，那么我们应该step_down等待他来vote
      |- 然后统一通过VoteBallot 这个投票箱来进行
        \- _pre_vote_ctx.grant(*it);
        |- _pre_vote_ctx.granted() 如果超过半数，那么就选举自己
   |-  elect_self; // 发起正式投票
   \- 状态转变为candidate， current_term++
    |- request_peers_to_vote给所有的peers发送vote请求，与prevote在request的区别可能就是current_term增加了
    |- handle_request_vote_response，与prevote的主要区别是become_leader
    \- become_leader: 给所有的peers注册replicate timer，并且发送一个empty entries（实际上与心跳很像，但是内部包含了日志修复）, 来确保log的commited；

handle_pre_vote_request
 |- 预投票检查（比正式投票检查少，因为确实不需要一些状态转换）
  1. req.term是否比自己的小，是则拒绝
  2. log index 比较
 |- 把自己的term放入
 |- 租约相关信息

handle_request_vote_request
1. 比较term是否比自己小
2. 取得log最新的index, 由于ABA问题，这里需要比较写cur_term与prev_term
3. 比较follower lease租约，如果没有过期，就不投票
4. 如果term新， leader setp_down降级
5. 如果log中req的更新，且没投票过，投票给他，_vote_id记录；保存本地投票结果到本地


> prevote gpt知识小结，可以我们关注到，发起方发起prevote的时候，其状态是follower的；
Raft算法的Pre-vote阶段是为了防止网络分区和服务器重启等问题导致的不必要的领导者选举。Pre-vote阶段的条件和要求如下：

发起方条件：

发起方只有在自己的状态为Follower或Candidate，并且在一段时间内没有收到Leader的心跳，才会启动Pre-vote阶段。
发起方在Pre-vote阶段会增加自己的term，并将自己的term和最后一条日志的index和term发送给其他节点。
响应方条件：

响应方接收到Pre-vote请求后，首先会和自己的term进行比较，如果请求的term小于自己的term，则拒绝请求。
如果请求的term等于或大于自己的term，响应方会比较自己的日志和请求中的日志，如果自己的日志比请求中的日志新，也会拒绝请求。
如果请求的term和日志都满足要求，响应方会将自己的状态设置为Follower，并返回同意Pre-vote的响应。
如果发起方收到了大多数节点（包括自己）的同意Pre-vote的响应，那么发起方将进入到真正的领导者选举阶段（vote阶段）。

注意：Pre-vote阶段不会改变节点的状态，也不会改变当前的term，只是一个预先的选举，用于测试是否有可能成功进行领导者选举。

### 日志复制
日志复制，实际上就是append_entries请求
_send_entries()、_send_empty_entries(bool is_heartbeat) 均会走到last_commited，但是但且仅当ballot完成了超过一般以上的节点grant之后，才会自增committed，这样，在后续的心跳和append entries中，才会继续更新follower节点的状态机。
\- Replicator::_fill_common_fields
 |- request->set_committed_index(_options.ballot_box->last_committed_index());

带有raft的请求原来是先append entries日志，然后才执行op，我们以example/atomic为例：
AtomicServiceImpl::exchange
\- Atomic::exchange
 \- apply(OP_EXCHANGE, request, response, done);
  \- Atomic::apply
   \- butil::IOBufAsZeroCopyOutputStream // 日志序列化
   |- NodeImpl::apply
   |- LogManager::append_entries
   \- LeaderStableClosure::Run()
    |- _ballot_box->commit_at
   |- wakeup_all_waiter(lck); // 唤醒所有的replicator的waiter任务，去执行append entries


tips：
braft使用了bthread的类似生产者消费者队列
// 构建消费者，消费函数是run
bthread::execution_queue_start(&_queue_id,
                                   &execq_opt,
                                   FSMCaller::run,
                                   this)
当一个数据执行完成后，会调用FSM状态机函数 
_waiter->on_committed(last_committed_index);
\_
 |- FSMCaller::on_committed
 \- bthread::execution_queue_execute(_queue_id, t);
  |- 而后会调用do_committed进行append entries发送


日志复制，是如何在follow上面确认的：
在Raft协议中，当leader发送append entries给follower并且收到了成功的响应后，leader会更新自己对应的follower的nextIndex和matchIndex。其中matchIndex记录的是该follower已经写入的日志的最大索引。
一旦leader更新了follower的matchIndex，它就会检查是否存在一个索引 N 和任意大于 N 的索引，使得大于等于半数的follower的matchIndex大于等于N，且索引N的日志条目的任期号等于leader当前的任期。如果存在，那么leader就会将自己的commitIndex更新为这个索引N。
当leader的commitIndex被更新后，leader会将更新后的commitIndex通过append entries RPC发送给所有的follower。当follower收到append entries RPC后，如果发现leader的commitIndex大于自己的commitIndex，那么follower就会将自己的commitIndex更新为leader的commitIndex。
这样，通过leader和follower之间的交互，就可以保证一旦一个日志条目被复制到了大多数的服务器上，那么这个日志条目就会被标记为committed。

通过上面，应该能够理解append entries是怎么发送以及response的，那么什么时候发送append entries请求呢？
tips: _on_rpc_returned是append entries的response函数，再得到对应的



### 日志Recovery
日志的recovery分为current term与prev term：
* current term的修复主要场景是follower因为故障退出集群，而后恢复后，leader对齐进行follower进行同步；
* prev term是在leader频繁切换+某个follower离线了一段时间的请求下才会出现，leader为每一个follower维护了一个nextId，标识下一个要发送的log index，Follower接收到AppendEntries之后会进行一些一致性检查，检查AppendEntries中指定的LastLogIndex是否一致，如果不一致就会向Leader返回失败。Leader接收到失败之后，会将nextId减1，重新进行发送，直到成功。


https://www.jianshu.com/p/82b9c268688e

在follower接收到append entries之后，需要进行term的判定：
handle_append_entries_request
// 如果prev的日志不匹配，应该需要直接进入log recovery状态
\-if (local_prev_log_term != request->prev_log_term()) 
 \- 返回失败，并且把follower的term返回给leader
  |- response->set_last_log_index(last_index);
  |- response->set_success(false);

在leader这端：
Replicator::_on_rpc_returned
\- if (!response->success()) {
 |- r->_reset_next_index();
 |- r->_next_index = response->last_log_index() + 1; 或者  --r->_next_index;
 |- r->_send_empty_entries(false);
 \- Replicator::_fill_common_fields
  \- _install_snapshot(); 如果本地找不到对应的log index
  |- stub.append_entries; 如果找到了则继续append entries

小结：braft的log recovery是比较纯粹的，在follower发现log index或者term不匹配的时候，会直接给leader返回自己的prev log index， 由leader来看当前是否适合install snapshot，如果不合适就继续发送log entries。
这里有个细节：
// 如果follower日志比我少，那我对齐他的日志同步就可以
if (response->last_log_index() + 1 < r->_next_index) {
|- r->_next_index = response->last_log_index() + 1;
// 如果follower日志比我多，那么他上面的一定是old term的，且必定没有committed，我们需要逐个回溯去对齐我们有重复的log index
|- --r->_next_index;


### snapshot

snapshot有两种模式：计时模式，接口模式，计量模式（计量模式没有实现，因为实时统计内存是一种相对耗时的操作）
handle_snapshot_timeout()
\- do_snapshot
 \- SnapshotExecutor::do_snapshot
  |- 创建snapshot writer
  |- SnapshotWriter* writer = 
   \- LocalSnapshotWriter::init
  |- SaveSnapshotDone* snapshot_save_done = new SaveSnapshotDone(this, writer, done);
  |- if (_fsm_caller->on_snapshot_save(snapshot_save_done) != 0) {
   \-  FSMCaller::do_snapshot_save
   |- SaveSnapshotDone::Run()

libraft内提供了基于文件列表的LocalSnapshotWriter和LocalSnapshotReader默认实现，具体使用方式为：
- 在fsm的on_snapshot_save回调中，将状态数据写入到本地文件中，然后调用SnapshotWriter::add_file将相应文件加入snapshot meta。
- 在fsm的on_snapshot_load回调中，调用SnapshotReader::list_files获取本地文件列表，按照on_snapshot_save的方式进行解析，恢复状态数据。

### membership change

参考：https://ku.baidu-int.com/knowledge/HFVrC7hq1Q/pKzJfZczuc/vx_oM591qA/w2qUKQG_6Fl8Bi
目前讨论raft的复制组都是基于一个假设：集群的整体配置是不变的
raft集群是需要支持动态的添加节点的，想想当前的接口，如果当前加入集群非常多的节点，那么可能会出现两个group，同时，由于各个节点的配置的更新是不同步的，这类问题使用2PC提交协议来解决, 具体步骤：
    // new_peers and old_peers during all conf-change stages, namely 
    // STAGE_CATCHING_UP->STAGE_JOINT->STAGE_STABLE
当发现配置变更后，节点会进入STAGE_CATCHING_UP状态；
流程上来说，client通知leader做配置变更：
1. 首先leader会直接应用new conf以及old conf，这里他的状态是转变为了STAGE_CATCHING_UP，此时leader会同时将new conf、old conf配置同时写入log entries并直接应用，本次应用是无需等待follower做投票应用的；
2. 如后续某条普通的entry要想被提交，必须同时存在于大多数的旧配置的server上，和大多数的新配置的server上；
  -> 但是在此期间，一个消息想要被应用，decision-making有可能是基于Cold，也有可能是基于Cold+new；
3. 当new+old conf应用的消息，被大多数node接收committed之后，集群就会进入joint-consensus（联合一致性）；
  -> 这里意味这后续的leader，必须要有old的大多数+new conf的大多数配置才可以被选举成功；
4. 当大多数new+old conf被接受之后， leader会发送new conf log entries应用，在new_conf应用期间
  -> new conf + old conf都是大多数的消息可以接收
  -> new conf的大多数消息可以接收
5. 最终 new conf应用后, 集群整体使用new conf来做决策

实质上，将整个集群可能的decison-making依赖的majority状态空间分成了5个阶段，分别是：
old中大多数做决定 →（old中的大多数做决定） 或者 （old和new中的大多数同时做决定）→（old和new中的大多数同时做决定）
→（old和new中的大多数同时做决定） 或者 （new中的大多数做决定）→ new中的大多数做决定

tips：如果变更期间，old conf被选举出leader，后续new conf相关的配置更新之后，该leader必定会step down

除了批量更新new conf，还有一种单点更新的方法：
0. new node追数据；
1. leader直接把新配置Cnew到 old + new个节点上
2. Commit这个新日志之后，就能保证以Cnew工作，在此之前，集群有可能是以Cnew方式工作(leader上是Cnew)，也有可能是以Cold工作 (发生切主，leader上是Cold)


