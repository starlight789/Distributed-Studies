# 写流程


![](/笔记/rocksdb/image/write.png)

1. MANIFEST 保存当前db的状态信息（类似于快照），主要是SST文件的各个版本信息（当sst文件被改动，即会生成对应的versionEdit，并触发sync写manifest文件），用于异常断电后恢复。
2. Memtable 常驻于内存中，在wal写之后写入key-value。
3. Immutable memtable ，当memtable被写满之后会生成一个新的memtable继续接受IO，旧的memtable就会变成 immutable memtable ，只读的状态，且开始flush到磁盘的L0。
4. SST文件，核心key-value的存储文件。


## 1. 框架

WAL的写入是单线程顺序串行写入的，而MemTable则是可以并发多线程写入。
单个操作写入wal和MemTable是顺序的，不同操作写入wal和MemTable可以并发，通过enable_pipelined_write控制。
- 优化串行写wal的瓶颈
- 通过设置参数enable_pipelined_write = true 来开启pipeline

开启pipeline后，写入逻辑如下：

### 3.1 整体代码流程
RocksDB 的写入口为 DBImpl::WriteImpl()，RocksDB 每个线程以Writer为载体，Writer中封装了WriteBatch（记录了要写入的所有数据）WriteOptions 中的配置以及前后向指针等等。
```c++
struct Writer {
  // 指向写入批次的指针，表示这个写入操作要写入的数据
  WriteBatch* batch;
  // 表示这个写入操作是否需要同步。如果为true，表示写入操作完成后需要立即将数据同步到磁盘
  bool sync;
  // 写入操作是否不允许被降速。如果为true，表示即使写入压力大，也不应降低这个写入操作的速度
  bool no_slowdown;
  // 写入操作是否禁用WAL（Write-Ahead Logging）。如果为true，表示这个写入操作不需要写入WAL
  bool disable_wal;
  // 枚举值，表示这个写入操作的I/O优先级。
  Env::IOPriority rate_limiter_priority;
  // 写入操作是否禁用MemTable。如果为true，表示这个写入操作不需要更新
  bool disable_memtable;
  size_t batch_cnt;  // if non-zero, number of sub-batches in the write batch
  size_t protection_bytes_per_key;
  // 指向回调函数的指针，表示在预发布阶段需要执行的动作。
  PreReleaseCallback* pre_release_callback;
  // 指向回调函数的指针，表示在更新MemTable后需要执行的动作。
  PostMemTableCallback* post_memtable_callback;
  // 这个批次被插入的日志编号
  uint64_t log_used;
  // MemTable插入应该引用的日志编号。
  uint64_t log_ref;
  // 回调函数的指针，表示写入操作完成后需要执行的动作。
  WriteCallback* callback;
  
  bool made_waitable;          // records lazy construction of mutex and cv
  // 原子变量，表示写入操作的状态。
  std::atomic<uint8_t> state;  // write under StateMutex() or pre-link
  // 指向写入组的指针，表示这个写入操作所在的写入组。
  WriteGroup* write_group;
  // 序列号，表示用于第一个键的序列号。
  SequenceNumber sequence;  // the sequence number to use for the first key
  // 状态码，表示写入操作的状态
  Status status;
  // 状态码，表示回调函数的返回状态。
  Status callback_status;  // status returned by callback->Callback()

  // 互斥锁的存储空间，用于保护状态的修改。
  std::aligned_storage<sizeof(std::mutex)>::type state_mutex_bytes;
  // 条件变量的存储空间，用于等待和通知状态的改变。
  std::aligned_storage<sizeof(std::condition_variable)>::type state_cv_bytes;
  // 指向旧写入操作的指针。
  Writer* link_older;  // read/write only before linking, or as leader
  // 指向新写入操作的指针。
  Writer* link_newer;  // lazy, read/write only before linking, or as leader
}
```
为了处理并发， RocksDB 将多个 Writer 对象用链表串起来，组成一个WiteGroup，一个 WriteGroup 会选出一个 Leader 来管理当前 group 的写过程。而任意时刻只会有一个WriteGroup被写入。

(1) 多线程的Write操作会首先入队列WriteThread::newest_writer_，入队之后如果发现自己是leader（队头），则继续如下操作，如果不是(2) leader是follower，则阻在WriteThread::AwaitState上
(3) leader将当前队列中所有的writer打入一个batch，然后写WAL和Memtable
(4) leader更新batch中的所有writer的state，然后选择当前队列中除batch外第一个writer当新的leader，唤醒新leader和batch中的followers
(5) 阻塞在WriteThread::AwaitState上的followers都被唤醒，发现自己的state已经被更新，直接返回

## DBImpl::WriteImpl()
#### --> WriteThread::JoinBatchGroup()
#### ---> WriteThread::LinkOne()
当前的Writer对象加入到group中，这里可以看到由于 写入是并发的因此对应的newest_writer_(保存最新的写入对象)需要原子操作来更新.

```c++
bool WriteThread::LinkOne(Writer* w, std::atomic<Writer*>* newest_writer) {
  assert(newest_writer != nullptr);
  assert(w->state == STATE_INIT);
  Writer* writers = newest_writer->load(std::memory_order_relaxed);
  while (true) {
    // If write stall in effect, and w->no_slowdown is not true,
    // block here until stall is cleared. If its true, then return
    // immediately
    if (writers == &write_stall_dummy_) {
      if (w->no_slowdown) {
        w->status = Status::Incomplete("Write stall");
        SetState(w, STATE_COMPLETED);
        return false;
      }
      // Since no_slowdown is false, wait here to be notified of the write
      // stall clearing
      {
        MutexLock lock(&stall_mu_);
        writers = newest_writer->load(std::memory_order_relaxed);
        if (writers == &write_stall_dummy_) {
          stall_cv_.Wait();
          // Load newest_writers_ again since it may have changed
          writers = newest_writer->load(std::memory_order_relaxed);
          continue;
        }
      }
    }
    w->link_older = writers;
    if (newest_writer->compare_exchange_weak(writers, w)) {
      return (writers == nullptr);
    }
  }
}
```
#### ---> WriteThread::AwaitState()
```c++
uint8_t WriteThread::AwaitState(Writer* w, uint8_t goal_mask,
                                AdaptationContext* ctx) {
  uint8_t state;

  // 1. Busy loop using "pause" for 1 micro sec
  // 2. Else SOMETIMES busy loop using "yield" for 100 micro sec (default)
  // 3. Else blocking wait

  // 这个方法的实现使用了自旋锁和阻塞等待两种方式。在等待的开始阶段，它先使用自旋锁进行忙等待，如果在一定次数的循环中没有达到目标状态，就改用阻塞等待。
  // 这样做的目的是为了在等待时间短的情况下避免频繁的上下文切换，提高程序的性能。
  for (uint32_t tries = 0; tries < 200; ++tries) {
    state = w->state.load(std::memory_order_acquire);
    if ((state & goal_mask) != 0) {
      return state;
    }
    port::AsmVolatilePause();
  }
  ......
}
```
#### --> EnterAsBatchGroupLeader()
当前的Writer对象为leader的话，则将会把此leader下的所有的write都 链接到一个WriteGroup中, 并开始写入WAL,这里要注意非leader的write将会直接 进入memtable的写入，这是因为非leader的write都将会被当前它所从属的leader来打包(group)写入。
#### --> WriteToWAL()
写WAL操作,最终会把这个write_group打包成一个writeBatch(通过MergeBatch函数)进行写入
#### --> LaunchParallelMemTableWriters()
逻辑类似写入WAL,如果是leader的话，则依旧会创建一个group(WriteGroup),然后遍历需要写入memtable的writer,将他们都加入到group中(EnterAsMemTableWriter),然后则设置并发执行的大小，以及设置对应状态(LaunchParallelMemTableWriters).这里注意每次setstate就将会唤醒之前阻塞的Writer.
在构造memtable的group的时候，我们不需要创建link_newer，因为之前在写入WAL的时候，我们已经构造好link_newer,那么此时我们使用构造好的group也就是表示这个group中包含的都是已经写入到WAL的操作.

#### --> Memtable写入状态检查
```c++
  if (w.state == WriteThread::STATE_PARALLEL_MEMTABLE_WRITER) {
    assert(w.ShouldWriteToMemtable());
    ColumnFamilyMemTablesImpl column_family_memtables(
        versions_->GetColumnFamilySet());
    w.status = WriteBatchInternal::InsertInto(
        &w, w.sequence, &column_family_memtables, &flush_scheduler_,
        write_options.ignore_missing_column_families, 0 /*log_number*/, this,
        true /*concurrent_memtable_writes*/);
    if (write_thread_.CompleteParallelMemTableWriter(&w)) {
      MemTableInsertStatusCheck(w.status);
      versions_->SetLastSequence(w.write_group->last_sequence);
      write_thread_.ExitAsMemTableWriter(&w, *w.write_group);
    }
  }
```
#### --> ExitAsMemTableWriter()
当前group的所有Writer都写入MemTable之后，则将会调用ExitAsMemTableWriter来进行收尾工作.如果有新的memtable writer list需要处理，那么则唤醒对应的Writer,然后设置已经处理完毕的Writer的状态.


```c++
Status DBImpl::WriteImpl(const WriteOptions& write_options,
                         WriteBatch* my_batch, WriteCallback* callback,
                         uint64_t* log_used, uint64_t log_ref,
                         bool disable_memtable, uint64_t* seq_used,
                         size_t batch_cnt,
                         PreReleaseCallback* pre_release_callback) {
  // 如果关闭了Memtable选项, 只需要写入WAL文件
  if (two_write_queues_ && disable_memtable) {
    return WriteImplWALOnly(write_options, my_batch, callback, log_used,
                            log_ref, seq_used, batch_cnt, pre_release_callback);
  }

  // 是否打开了pipelined写入方式
  if (immutable_db_options_.enable_pipelined_write) {
    return PipelinedWriteImpl(write_options, my_batch, callback, log_used,
                              log_ref, disable_memtable, seq_used);
  }

  // 新建一个writer
  WriteThread::Writer w(write_options, my_batch, callback, log_ref,
                        disable_memtable, batch_cnt, pre_release_callback);

  // 将writer加入一个batch队列中
  write_thread_.JoinBatchGroup(&w);
  // 判断返回的状态是否为并行写memtable的leader
  if (w.state == WriteThread::STATE_PARALLEL_MEMTABLE_WRITER) {
    // 应该写入memtable
    if (w.ShouldWriteToMemtable()) {
      PERF_TIMER_STOP(write_pre_and_post_process_time);
      PERF_TIMER_GUARD(write_memtable_time);

      ColumnFamilyMemTablesImpl column_family_memtables(
          versions_->GetColumnFamilySet());
      w.status = WriteBatchInternal::InsertInto(
          &w, w.sequence, &column_family_memtables, &flush_scheduler_,
          write_options.ignore_missing_column_families, 0 /*log_number*/, this,
          true /*concurrent_memtable_writes*/, seq_per_batch_, w.batch_cnt);

      PERF_TIMER_START(write_pre_and_post_process_time);
    }

    // 检查memtable的写入任务是否全部已经完成，假如完成，最后一个writer以leader的角色退出，
    // 并会选出下一个batch的leader
    if (write_thread_.CompleteParallelMemTableWriter(&w)) {
      // we're responsible for exit batch group
      for (auto* writer : *(w.write_group)) {
        if (!writer->CallbackFailed() && writer->pre_release_callback) {
          assert(writer->sequence != kMaxSequenceNumber);
          Status ws = writer->pre_release_callback->Callback(writer->sequence,
                                                             disable_memtable);
          if (!ws.ok()) {
            status = ws;
            break;
          }
        }
      }
      // 假如还有writer在进行写入，自己就以follwer的角色退出，仅设置自己的状态
      auto last_sequence = w.write_group->last_sequence;
      versions_->SetLastSequence(last_sequence);
      MemTableInsertStatusCheck(w.status);
      write_thread_.ExitAsBatchGroupFollower(&w);
    }
    assert(w.state == WriteThread::STATE_COMPLETED);
    // STATE_COMPLETED conditional below handles exit

    status = w.FinalStatus();
  }
  // 假如退出时的状态为STATE_COMPLETED, 则写入任务已经完成，则退出
  if (w.state == WriteThread::STATE_COMPLETED) {
    if (log_used != nullptr) {
      *log_used = w.log_used;
    }
    if (seq_used != nullptr) {
      *seq_used = w.sequence;
    }
    // write is complete and leader has updated sequence
    return w.FinalStatus();
  }
  // 下面处理状态为STATE_GROUP_LEADER，即作为整个batch的leader的情况
  assert(w.state == WriteThread::STATE_GROUP_LEADER);

  // leader选择其他writer加入整个batch中
  last_batch_group_size_ =
      write_thread_.EnterAsBatchGroupLeader(&w, &write_group);

  if (status.ok()) {
    // ...
    if (!two_write_queues_) {
      if (status.ok() && !write_options.disableWAL) {
        PERF_TIMER_GUARD(write_wal_time);
        // 写入WAL文件
        status = WriteToWAL(write_group, log_writer, log_used, need_log_sync,
                            need_log_dir_sync, last_sequence + 1);
      }
    } else {
      if (status.ok() && !write_options.disableWAL) {
        PERF_TIMER_GUARD(write_wal_time);
        // LastAllocatedSequence is increased inside WriteToWAL under
        // wal_write_mutex_ to ensure ordered events in WAL
        status = ConcurrentWriteToWAL(write_group, log_used, &last_sequence,
                                      seq_inc);
      } else {
        // Otherwise we inc seq number for memtable writes
        last_sequence = versions_->FetchAddLastAllocatedSequence(seq_inc);
      }
    }
    assert(last_sequence != kMaxSequenceNumber);
    const SequenceNumber current_sequence = last_sequence + 1;
    last_sequence += seq_inc;

    if (status.ok()) {
      PERF_TIMER_GUARD(write_memtable_time);

      if (!parallel) {
        // 假如没有开启并行写memtable
        w.status = WriteBatchInternal::InsertInto(
            write_group, current_sequence, column_family_memtables_.get(),
            &flush_scheduler_, write_options.ignore_missing_column_families,
            0 /*recovery_log_number*/, this, parallel, seq_per_batch_);
      } else {
        // ...
        // 唤醒其他的writer写入各自的memtable
        write_thread_.LaunchParallelMemTableWriters(&write_group);
        in_parallel_group = true;

        // leader判断是否需要写入memtable, 如果需要，仅完成自己的memtable的写入
        if (w.ShouldWriteToMemtable()) {
          ColumnFamilyMemTablesImpl column_family_memtables(
              versions_->GetColumnFamilySet());
          assert(w.sequence == current_sequence);
          w.status = WriteBatchInternal::InsertInto(
              &w, w.sequence, &column_family_memtables, &flush_scheduler_,
              write_options.ignore_missing_column_families, 0 /*log_number*/,
              this, true /*concurrent_memtable_writes*/, seq_per_batch_,
              w.batch_cnt);
        }
      }
      if (seq_used != nullptr) {
        *seq_used = w.sequence;
      }
    }
  }
  PERF_TIMER_START(write_pre_and_post_process_time);

  // ...
  // 假如开启了并行写，判断目前的memtable写入状况
  bool should_exit_batch_group = true;
  if (in_parallel_group) {
    // CompleteParallelWorker returns true if this thread should
    // handle exit, false means somebody else did
    should_exit_batch_group = write_thread_.CompleteParallelMemTableWriter(&w);
  }
  // 假如Leader作为整个batch的最后一个写入完成的writer, 则设置其他的writer状态并选出下一个batch的
  // leader，退出
  if (should_exit_batch_group) {
    // ...
    write_thread_.ExitAsBatchGroupLeader(write_group, status);
  }

  if (status.ok()) {
    status = w.FinalStatus();
  }
  return status;
}
```

### 调优参数设置：
options.OptimizeLevelStyleCompaction();总体上的一个参数调整是增加memtable的吞吐量：增加了memtable的大小，可以同时存在于内存中的memtable文件的个数，并且适配了L1的容量保持和L0的容量接近，还有一些各层的压缩算法的配置。大概测试了一下该配置的随机写吞吐能够在原有基础之上提升50-80%。不过该配置肯定对内存资源的消耗比较大，所以如果系统资源足够且是IO密集型业务对性能有较高的要求可以尝试一下该配置。
options.allow_concurrent_memtable_write=true ; 允许多个writer 对memtable的并发写入
options.enable_pipelined_write=true ; 开启pipeline的写机制，允许memtable和wal并发写入


参考： https://vigourtyy-zhg.blog.csdn.net/article/details/106367782